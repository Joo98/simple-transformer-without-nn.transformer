# simple-transformer-without-nn.transformer
### 아래 링크의 나동빈님의 코드를 많이 참고하였습니다.
https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Attention_is_All_You_Need_Tutorial_(German_English).ipynb

### 공부를 하는 학생의 입장에서 많은 부분이 같은 코드를 사용하지만 모든 코드를 이해하고 구현 과정에서 주석을 더 달아가면서 공부하였습니다.
### dropout 기법에 대한 학습이 미숙하여 해당 코드를 제거하였으며 이로 인해서 학습시간이 높아져 모델의 디멘션을 줄였습니다.
